<!DOCTYPE html>
<html lang="en-us">
<head>

  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="theme" content="hugo-academic">
  <meta name="generator" content="Hugo 0.41" />
  <meta name="author" content="Desh Raj">

  
  
  
  
    
      
    
  
  <meta name="description" content="Since I started working on speech recognition, I have only ever evaluated results using Word Error Rate (WER) metrics. Often, when some method performed differently on different datasets, senior researchers in my lab have told me it is &ldquo;too noisy&rdquo;, or has &ldquo;different channel characteristics&rdquo;. I have learnt about read speech and conversational speech, and how an ASR system needs to be robust to several variations in the utterance.">

  
  <link rel="alternate" hreflang="en-us" href="https://desh2608.github.io/post/asr-data/">

  


  

  
  
  <meta name="theme-color" content="#3f51b5">
  
  
  
  
    
  
  
    
    
      
        <link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/github.min.css">
      
    
  
  
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.3.7/css/bootstrap.min.css" integrity="sha512-6MXa8B6uaO18Hid6blRMetEIoPqHf7Ux1tnyIQdpt9qI5OACx7C+O3IVTr98vwGnlcg0LOLa02i9Y1HpVhlfiw==" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.8.6/css/academicons.min.css" integrity="sha256-uFVgMKfistnJAfoCUQigIl+JfUaP47GrRKjf6CTPVmw=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css" integrity="sha512-SfTiTlX6kk+qitfevl/7LibUOeJWlt9rbyDn92a1DqWOw9vWG2MFoays0sgObmWazO5BQPiFucnnEAjpAB+/Sw==" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.2.5/jquery.fancybox.min.css" integrity="sha256-ygkqlh3CYSUri3LhQxzdcm0n1EQvH2Y+U5S2idbLtxs=" crossorigin="anonymous">
  
  
  
  
  <link rel="stylesheet" href="//fonts.googleapis.com/css?family=Lato:400,700%7cMerriweather%7cRoboto&#43;Mono">
  
  <link rel="stylesheet" href="/styles.css">
  

  
    <script>
      window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
      ga('create', 'UA-121781547-1', 'auto');
      
      ga('require', 'eventTracker');
      ga('require', 'outboundLinkTracker');
      ga('require', 'urlChangeTracker');
      ga('send', 'pageview');
    </script>
    <script async src="//www.google-analytics.com/analytics.js"></script>
    
    <script async src="https://cdnjs.cloudflare.com/ajax/libs/autotrack/2.4.1/autotrack.js" integrity="sha512-HUmooslVKj4m6OBu0OgzjXXr+QuFYy/k7eLI5jdeEy/F4RSgMn6XRWRGkFi5IFaFgy7uFTkegp3Z0XnJf3Jq+g==" crossorigin="anonymous"></script>
    
  

  
  <link rel="alternate" href="https://desh2608.github.io/index.xml" type="application/rss+xml" title="Desh Raj">
  <link rel="feed" href="https://desh2608.github.io/index.xml" type="application/rss+xml" title="Desh Raj">
  

  <link rel="manifest" href="/site.webmanifest">
  <link rel="icon" type="image/png" href="/img/icon.png">
  <link rel="apple-touch-icon" type="image/png" href="/img/icon-192.png">

  <link rel="canonical" href="https://desh2608.github.io/post/asr-data/">

  <meta property="twitter:card" content="summary_large_image">
  
  <meta property="twitter:site" content="@https://twitter.com/rdesh26">
  <meta property="twitter:creator" content="@https://twitter.com/rdesh26">
  
  <meta property="og:site_name" content="Desh Raj">
  <meta property="og:url" content="https://desh2608.github.io/post/asr-data/">
  <meta property="og:title" content="What do speech datasets sound like? | Desh Raj">
  <meta property="og:description" content="Since I started working on speech recognition, I have only ever evaluated results using Word Error Rate (WER) metrics. Often, when some method performed differently on different datasets, senior researchers in my lab have told me it is &ldquo;too noisy&rdquo;, or has &ldquo;different channel characteristics&rdquo;. I have learnt about read speech and conversational speech, and how an ASR system needs to be robust to several variations in the utterance.">
  <meta property="og:locale" content="en-us">
  
  <meta property="article:published_time" content="2019-04-11T20:10:35-04:00">
  
  <meta property="article:modified_time" content="2019-04-12T11:09:52-04:00">
  

  
  

  <title>What do speech datasets sound like? | Desh Raj</title>

</head>
<body id="top" data-spy="scroll" data-target="#toc" data-offset="71" >

<nav class="navbar navbar-default navbar-fixed-top" id="navbar-main">
  <div class="container">

    
    <div class="navbar-header">
      
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse"
              data-target=".navbar-collapse" aria-expanded="false">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      
      <a class="navbar-brand" href="/">Desh Raj</a>
    </div>

    
    <div class="collapse navbar-collapse">

      
      
      <ul class="nav navbar-nav navbar-right">
        

        
        
        
        
        
          
        

        <li class="nav-item">
          <a href="/#about">
            
            <span>Home</span>
            
          </a>
        </li>

        
        

        
        
        
        
        
          
        

        <li class="nav-item">
          <a href="/#publications">
            
            <span>Publications</span>
            
          </a>
        </li>

        
        

        
        
        
        
        
          
        

        <li class="nav-item">
          <a href="/#talks">
            
            <span>Talks</span>
            
          </a>
        </li>

        
        

        
        
        
        
        
          
        

        <li class="nav-item">
          <a href="/#posts">
            
            <span>Posts</span>
            
          </a>
        </li>

        
        

        
        
        
        
        
          
        

        <li class="nav-item">
          <a href="/#contact">
            
            <span>Contact</span>
            
          </a>
        </li>

        
        
      

      
      </ul>

    </div>
  </div>
</nav>


<article class="article" itemscope itemtype="http://schema.org/Article">

  


  <div class="article-container">
    <h1 itemprop="name">What do speech datasets sound like?</h1>

    

<div class="article-metadata">

  <span class="article-date">
    
        Last updated on
    
    <time datetime="2019-04-11 20:10:35 -0400 EDT" itemprop="datePublished dateModified">
      Apr 12, 2019
    </time>
  </span>
  <span itemscope itemprop="author publisher" itemtype="http://schema.org/Person">
    <meta itemprop="name" content="Desh Raj">
  </span>

  
  <span class="middot-divider"></span>
  <span class="article-reading-time">
    4 min read
  </span>
  

  
  
  <span class="middot-divider"></span>
  <a href="https://desh2608.github.io/post/asr-data/#disqus_thread"></a>
  

  
  
  
  

  
  
<div class="share-box" aria-hidden="true">
  <ul class="share">
    <li>
      <a class="twitter"
         href="https://twitter.com/intent/tweet?text=What%20do%20speech%20datasets%20sound%20like%3f&amp;url=https%3a%2f%2fdesh2608.github.io%2fpost%2fasr-data%2f"
         target="_blank" rel="noopener">
        <i class="fa fa-twitter"></i>
      </a>
    </li>
    <li>
      <a class="facebook"
         href="https://www.facebook.com/sharer.php?u=https%3a%2f%2fdesh2608.github.io%2fpost%2fasr-data%2f"
         target="_blank" rel="noopener">
        <i class="fa fa-facebook"></i>
      </a>
    </li>
    <li>
      <a class="linkedin"
         href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https%3a%2f%2fdesh2608.github.io%2fpost%2fasr-data%2f&amp;title=What%20do%20speech%20datasets%20sound%20like%3f"
         target="_blank" rel="noopener">
        <i class="fa fa-linkedin"></i>
      </a>
    </li>
    <li>
      <a class="weibo"
         href="http://service.weibo.com/share/share.php?url=https%3a%2f%2fdesh2608.github.io%2fpost%2fasr-data%2f&amp;title=What%20do%20speech%20datasets%20sound%20like%3f"
         target="_blank" rel="noopener">
        <i class="fa fa-weibo"></i>
      </a>
    </li>
    <li>
      <a class="email"
         href="mailto:?subject=What%20do%20speech%20datasets%20sound%20like%3f&amp;body=https%3a%2f%2fdesh2608.github.io%2fpost%2fasr-data%2f">
        <i class="fa fa-envelope"></i>
      </a>
    </li>
  </ul>
</div>


  

</div>


    <div class="article-style" itemprop="articleBody">
      

<p>Since I started working on speech recognition, I have only ever evaluated results using Word Error Rate (WER) metrics. Often, when some method performed differently on different datasets, senior researchers in my lab have told me it is &ldquo;too noisy&rdquo;, or has &ldquo;different channel characteristics&rdquo;. I have learnt about read speech and conversational speech, and how an ASR system needs to be robust to several variations in the utterance.</p>

<p>However, I have not once actually listened to these datasets to understand how complex the task is. I think many amateur researchers make this error starting out, since the data and recipes (in Kaldi, at least) are so nicely constructed, that you just tend to think of the speech data as a bunch of MFCC vectors.</p>

<p>In this article, I put samples of several popular corpora used in ASR research, along with their characteristics and my impression of how they sound. The resource descriptions, in most cases, are taken from their respective <a href="https://github.com/kaldi-asr/kaldi/tree/master/egs" target="_blank">Kaldi</a> recipes.</p>

<p><em>Disclaimer</em>: Some of these datasets are proprietary, and I don&rsquo;t really know if sharing a small sample is permitted under the license. If you know about the particulars, please send me a mail at <code>draj@cs.jhu.edu</code> and I will update the post.</p>

<h4 id="resource-management-rm-https-catalog-ldc-upenn-edu-ldc93s3c"><a href="https://catalog.ldc.upenn.edu/LDC93S3C" target="_blank">Resource Management (RM)</a></h4>

<p>Clean speech in a medium-vocabulary task consisting of commands to a (presumably imaginary) computer system. About 3 hours of training data.</p>




<audio controls style="width: 100%; margin-bottom: 20px">
    <source src="/files/asr/rm.wav" type="audio/wav">
    Your browser does not support the audio element.
</audio>

<p>Here is a transcription of the above sample: <em>SHOW THE GRIDLEY+S TRACK IN BRIGHT ORANGE WITH HORNE+S IN DIM RED</em>.</p>

<p>The sample sounds distinctly synthetic, and does not have any noise. As such, it is among the easiest datasets for ASR, and is often used for a <em>Hello World</em> equivalent for ASR systems.</p>

<h4 id="babel-https-en-wikipedia-org-wiki-babel-speech-corpus"><a href="https://en.wikipedia.org/wiki/BABEL_Speech_Corpus" target="_blank">Babel</a></h4>

<p>The first version of Babel was recorded speech in 5 European languages (as mentioned on the Wiki), but the current version in Kaldi consists of 9 non-European languages like Assamese, Cantonese, Turkish, etc. Here is a sample from the Babel Bengali.</p>




<audio controls style="width: 100%; margin-bottom: 20px">
    <source src="/files/asr/babel.wav" type="audio/wav">
    Your browser does not support the audio element.
</audio>

<p>It sounds like conversational speech recorded at one end of a telephone conversation. There are several silences, which would correspond to the other person speaking (which is not recorded). There is a static noise in the background as well.</p>

<h4 id="switchboard-https-www-isip-piconepress-com-projects-switchboard"><a href="https://www.isip.piconepress.com/projects/switchboard/" target="_blank">Switchboard</a></h4>

<p>This is telephonic speech in English released in 1997, collected as a 2-channel, 8kHz-sampled data. Here is a sample.</p>




<audio controls style="width: 100%; margin-bottom: 20px">
    <source src="/files/asr/swbd.wav" type="audio/wav">
    Your browser does not support the audio element.
</audio>

<p>It sounds similar to the Babel corpus, except that it is entirely in English and a little cleaner.</p>

<h4 id="fisher-english-https-catalog-ldc-upenn-edu-ldc2004s13"><a href="https://catalog.ldc.upenn.edu/LDC2004S13" target="_blank">Fisher English</a></h4>

<p>This is conversational telephone speech collected as 2-channel, 8kHz-sampled data.  The data is similar to Switchboard but the transcription was mostly done in a &ldquo;faster&rdquo;, lower-quality way. Here is a sample.</p>




<audio controls style="width: 100%; margin-bottom: 20px">
    <source src="/files/asr/fe.wav" type="audio/wav">
    Your browser does not support the audio element.
</audio>

<h4 id="librispeech-http-www-openslr-org-12"><a href="http://www.openslr.org/12/" target="_blank">Librispeech</a></h4>

<p>LibriSpeech is a corpus of approximately 1000 hours of 16kHz read English speech, prepared by Vassil Panayotov with the assistance of Daniel Povey. The data is derived from read audiobooks from the LibriVox project, and has been carefully segmented and aligned. There is a smaller version called <a href="http://www.openslr.org/31/" target="_blank"><code>mini_librispeech</code></a> created for the purpose of regression testing. Here is a sample.</p>




<audio controls style="width: 100%; margin-bottom: 20px">
    <source src="/files/asr/libri.wav" type="audio/wav">
    Your browser does not support the audio element.
</audio>

<p>The transcription for the above sample: <em>as you know and as i have given you proof i have the greatest admiration in the world for one whose work for humanity has won such universal recognition i hope that we shall both forget this unhappy morning and that you will give me an opportunity of rendering to you in person</em></p>

<p>As is evident, this is read speech, and would probably be much easier to transcribe than the earlier datasets.</p>

<h4 id="ted-lium-http-www-openslr-org-7"><a href="http://www.openslr.org/7/" target="_blank">TED-LIUM</a></h4>

<p>The TED-LIUM corpus is English-language TED talks, with transcriptions, sampled at 16kHz. It contains about 118 hours of speech. Here is a sample.</p>




<audio controls style="width: 100%; margin-bottom: 20px">
    <source src="/files/asr/tedlium.wav" type="audio/wav">
    Your browser does not support the audio element.
</audio>

<p>We can see that the difficulty of transcription may be between a read speech and a conversational speech. There are very few silences, unlike the telephonic speech corpora, but there is still some background noise and reverberation since these are recorded talks.</p>

<h4 id="timit-https-en-wikipedia-org-wiki-timit"><a href="https://en.wikipedia.org/wiki/TIMIT" target="_blank">TIMIT</a></h4>

<p>The TIMIT corpus of read speech is designed to provide speech data for acoustic-phonetic studies and for the development and evaluation of automatic speech recognition systems. TIMIT contains broadband recordings of 630 speakers of eight major dialects of American English, each reading ten phonetically rich sentences. The TIMIT corpus includes time-aligned orthographic, phonetic and word transcriptions as well as a 16-bit, 16kHz speech waveform file for each utterance. Here is a sample.</p>




<audio controls style="width: 100%; margin-bottom: 20px">
    <source src="/files/asr/timit.wav" type="audio/wav">
    Your browser does not support the audio element.
</audio>

<h4 id="wall-street-journal-wsj-https-catalog-ldc-upenn-edu-ldc93s6a"><a href="https://catalog.ldc.upenn.edu/LDC93S6A" target="_blank">Wall Street Journal (WSJ)</a></h4>

<p>This is a corpus of read sentences from the Wall Street Journal, recorded under clean conditions. The vocabulary is quite large. About 80 hours of training data. Here is a sample.</p>




<audio controls style="width: 100%; margin-bottom: 20px">
    <source src="/files/asr/wsj.wav" type="audio/wav">
    Your browser does not support the audio element.
</audio>

<p>As is clear, TIMIT and WSJ sound very similar, but the spoken content differs greatly.</p>

    </div>

    





    
    

    

    
<section id="comments">
  <div id="disqus_thread"></div>
<script>
    var disqus_config = function () {
    
    
    
    };
    (function() {
        if (["localhost", "127.0.0.1"].indexOf(window.location.hostname) != -1) {
            document.getElementById('disqus_thread').innerHTML = 'Disqus comments not available by default when the website is previewed locally.';
            return;
        }
        var d = document, s = d.createElement('script'); s.async = true;
        s.src = '//' + "desh2608-github-io" + '.disqus.com/embed.js';
        s.setAttribute('data-timestamp', +new Date());
        (d.head || d.body).appendChild(s);
    })();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
<a href="https://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>
</section>



  </div>
</article>

<footer class="site-footer">
  <div class="container">
    <p class="powered-by">

      &copy; 2018 &middot; 

      Powered by the
      <a href="https://sourcethemes.com/academic/" target="_blank" rel="noopener">Academic theme</a> for
      <a href="https://gohugo.io" target="_blank" rel="noopener">Hugo</a>.

      <span class="pull-right" aria-hidden="true">
        <a href="#" id="back_to_top">
          <span class="button_icon">
            <i class="fa fa-chevron-up fa-2x"></i>
          </span>
        </a>
      </span>

    </p>
  </div>
</footer>


<div id="modal" class="modal fade" role="dialog">
  <div class="modal-dialog">
    <div class="modal-content">
      <div class="modal-header">
        <button type="button" class="close btn-large" data-dismiss="modal">&times;</button>
        <h4 class="modal-title">Cite</h4>
      </div>
      <div>
        <pre><code class="modal-body tex"></code></pre>
      </div>
      <div class="modal-footer">
        <a class="btn btn-primary btn-outline js-copy-cite" href="#" target="_blank">
          <i class="fa fa-copy"></i> Copy
        </a>
        <a class="btn btn-primary btn-outline js-download-cite" href="#" target="_blank">
          <i class="fa fa-download"></i> Download
        </a>
        <div id="modal-error"></div>
      </div>
    </div>
  </div>
</div>

    

    
    
    <script id="dsq-count-scr" src="//desh2608-github-io.disqus.com/count.js" async></script>
    

    

    
    <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.2.1/jquery.min.js" integrity="sha512-3P8rXCuGJdNZOnUx/03c1jOTnMn3rP63nBip5gOP2qmUh5YAdVAvFZ1E+QLZZbC1rtMrQb+mah3AfYW11RUrWA==" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.imagesloaded/4.1.3/imagesloaded.pkgd.min.js" integrity="sha512-umsR78NN0D23AzgoZ11K7raBD+R6hqKojyBZs1w8WvYlsI+QuKRGBx3LFCwhatzBunCjDuJpDHwxD13sLMbpRA==" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.3.7/js/bootstrap.min.js" integrity="sha512-iztkobsvnjKfAtTNdHkGVjAYTrrtlC7mGp/54c40wowO7LhURYl3gVzzcEqGl/qKXQltJ2HwMrdLcNUdo+N/RQ==" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.isotope/3.0.4/isotope.pkgd.min.js" integrity="sha512-VDBOIlDbuC4VWxGJNmuFRQ0Li0SKkDpmGyuhAG5LTDLd/dJ/S0WMVxriR2Y+CyPL5gzjpN4f/6iqWVBJlht0tQ==" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.2.5/jquery.fancybox.min.js" integrity="sha256-X5PoE3KU5l+JcX+w09p/wHl9AzK333C4hJ2I9S5mD4M=" crossorigin="anonymous"></script>
    
    
    <script src="/js/hugo-academic.js"></script>
    

    
    
      
      
      <script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js" integrity="sha256-/BfiIkHlHoVihZdc6TFuj7MmJ0TWcWsMXkeDFwhi0zw=" crossorigin="anonymous"></script>
      

      
      <script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/languages/python.min.js"></script>
      
      <script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/languages/cpp.min.js"></script>
      

      

      <script>hljs.initHighlightingOnLoad();</script>
    

    
    
    <script type="text/x-mathjax-config">
        MathJax.Hub.Config({ tex2jax: { inlineMath: [['$','$'], ['\\(','\\)']] } });
    </script>
    
    <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS_CHTML" integrity="sha512-tOav5w1OjvsSJzePRtt2uQPFwBoHt1VZcUq8l8nm5284LEKE9FSJBQryzMBzHxY5P0zRdNqEcpLIRVYFNgu1jw==" crossorigin="anonymous"></script>
    
    

  </body>
</html>

