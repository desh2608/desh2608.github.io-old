<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Deep learning on Desh Raj</title>
    <link>https://desh2608.github.io/tags/deep-learning/</link>
    <description>Recent content in Deep learning on Desh Raj</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>&amp;copy; 2018</copyright>
    <lastBuildDate>Tue, 03 Jul 2018 16:56:46 +0530</lastBuildDate>
    
	<atom:link href="https://desh2608.github.io/tags/deep-learning/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Waldo: A system for optical character recognition</title>
      <link>https://desh2608.github.io/project/waldo-ocr/</link>
      <pubDate>Tue, 03 Jul 2018 16:56:46 +0530</pubDate>
      
      <guid>https://desh2608.github.io/project/waldo-ocr/</guid>
      <description>It is an ongoing project under Prof. Daniel Povey to develop an Optical Character Recognition system that is robust on focused as well as incidental text. My contributions are:
 Experimenting with the ICDAR 2015 Robust Reading Challenge dataset by modifying training script. A visualization and compression module for segmentation mask overlayed on images.  The system consists of a modified UNet first proposed in this paper.</description>
    </item>
    
    <item>
      <title>Irony detection in tweets</title>
      <link>https://desh2608.github.io/project/irony-tweet/</link>
      <pubDate>Tue, 20 Mar 2018 17:00:16 +0530</pubDate>
      
      <guid>https://desh2608.github.io/project/irony-tweet/</guid>
      <description>The task was to recognize whether a tweet has irony or not - binary classification. In essence, we identified 2 aspects that were essential to identify irony in tweets:
 Semantic interaction between text and hashtags, modeled using holographic embeddings (or circular cross-correlations). World knowledge about irony in text, obtained through transfer learning from DeepMoji.  We were able to obtain a validation accuracy of 69%, although the model performed poorly in the final test phase.</description>
    </item>
    
    <item>
      <title>Understanding Word Vectors</title>
      <link>https://desh2608.github.io/post/understanding-word-vectors/</link>
      <pubDate>Fri, 29 Sep 2017 11:12:55 +0530</pubDate>
      
      <guid>https://desh2608.github.io/post/understanding-word-vectors/</guid>
      <description>This article is a formal representation of my understanding of vector semantics, from course notes and reading reference papers and chapters from Jurafsky’s SLP book. I will be talking about sparse and dense vector semantics, including SVD, skip-gram, and GloVe. In many places, I will try to explain the ideas in language rather than equations (but I’ll provide links to derivations and stuff wherever it is absolutely essential, which is actually everywhere!</description>
    </item>
    
    <item>
      <title>Learning local and global context using a convolutional recurrent network model for relation classification in biomedical text</title>
      <link>https://desh2608.github.io/publication/conll-17-learning/</link>
      <pubDate>Tue, 01 Aug 2017 00:00:00 +0000</pubDate>
      
      <guid>https://desh2608.github.io/publication/conll-17-learning/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Relation extraction for clinical text</title>
      <link>https://desh2608.github.io/project/btp/</link>
      <pubDate>Sun, 30 Apr 2017 17:00:24 +0530</pubDate>
      
      <guid>https://desh2608.github.io/project/btp/</guid>
      <description>The objective of the project was to devise a method for obtaining structured triplets from unstructured clinical records such as journal articles, patient health records etc. Simplifying this objective, I was tasked with creating a neural technique which can classify relations existing between entities in a given sentence, an NLP task known as relation classification.
The key insight is that convolutions can capture short-term phrases, while recurrence learns long-term dependencies. Combining both, we proposed the CRNN model which outperformed earlier single and double layer methods on two benchmark datasets: i2b2-2010 and DDI.</description>
    </item>
    
    <item>
      <title>Sptial Transformer Networks</title>
      <link>https://desh2608.github.io/project/stn/</link>
      <pubDate>Sun, 20 Nov 2016 17:00:42 +0530</pubDate>
      
      <guid>https://desh2608.github.io/project/stn/</guid>
      <description>Jaderberg et al. proposed the Spatial Transformer Network in NIPS 2015 in order to improve the classification of transformed images (i.e., images with affine transformation). In this project, we achieved 2 objectives:
 Improved the STN architecture by applying a recurrence in the outermost layer, i.e., transformed images are again fed into the module for further processing. Applied the network to egocentric image data to improve benchmark datasets like GTEA and Intel Egocentric Vision data.</description>
    </item>
    
  </channel>
</rss>